# ðŸš€ SCALE_TO_5000.md - Distributed Architecture & Session Persistence

**Goal:** Transition Python-Duel from 50 concurrent users (in-memory) to 5,000 concurrent users (distributed, Redis + PostgreSQL).

---

## PART 1: In-Memory â†’ Redis Matchmaking

### Current Architecture (50 Users - In-Memory)

**File:** [`backend/src/services/matchmaking.py`](backend/src/services/matchmaking.py)

```python
class MatchmakingQueue:
    def __init__(self):
        self.queue: List[Player] = []
        self.battle_rooms: Dict[str, BattleRoom] = {}
        self.player_to_room: Dict[str, str] = {}
```

**Problems at Scale:**
- âŒ Queue lost on server restart
- âŒ Cannot distribute across multiple servers
- âŒ Single point of failure
- âŒ No player persistence

---

### Distributed Architecture (5,000 Users - Redis)

#### **Architecture Diagram**

```
                    LOAD BALANCER (nginx)
                    /          \
                   /            \
          SERVER 1              SERVER 2
        (FastAPI)               (FastAPI)
           /  \                   /  \
          /    \                 /    \
      Socket  API            Socket  API
         |                      |
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
              REDIS CLUSTER
              â”œâ”€ queue:users
              â”œâ”€ battle:rooms:*
              â”œâ”€ player:state:*
              â””â”€ session:*
              
              PostgreSQL (Persistence)
              â”œâ”€ users
              â”œâ”€ battles (history)
              â””â”€ elo_ratings
```

---

## Step 1: Install Redis

```bash
# Option A: Docker (Recommended)
docker run -d -p 6379:6379 redis:7-alpine

# Option B: Local installation
# macOS: brew install redis
# Ubuntu: sudo apt install redis-server
# Windows: Download from https://github.com/microsoftarchive/redis

# Verify connection
redis-cli ping  # Should return PONG
```

---

## Step 2: Replace In-Memory Matchmaking with Redis

**File:** `backend/src/services/redis_matchmaking.py` (NEW)

```python
"""
Distributed matchmaking using Redis as backend.
Replaces in-memory matchmaking.py for horizontal scaling.
"""

import redis
import json
import uuid
from typing import Optional, Dict, List, Any
from dataclasses import dataclass, asdict
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

# Redis connection (centralized for all servers)
redis_client = redis.Redis(
    host=os.getenv('REDIS_HOST', 'localhost'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    db=0,
    decode_responses=True  # Return strings, not bytes
)


@dataclass
class Player:
    """Player data (JSON-serializable)."""
    user_id: str
    username: str
    elo_rating: int = 1000
    queue_time: str = None  # ISO format
    socket_id: str = ""
    
    def to_json(self) -> str:
        return json.dumps(asdict(self))
    
    @staticmethod
    def from_json(data: str) -> 'Player':
        d = json.loads(data)
        return Player(**d)


class RedisMatchmakingQueue:
    """Distributed queue using Redis."""
    
    def __init__(self):
        self.redis = redis_client
        
        # Redis key prefixes
        self.QUEUE_KEY = "queue:global"              # Sorted set of user IDs
        self.PLAYER_KEY_PREFIX = "player:"           # player:{user_id}
        self.ROOM_KEY_PREFIX = "room:"               # room:{room_id}
        self.PLAYER_TO_ROOM_KEY = "player_room:"     # player_room:{user_id}
    
    def add_to_queue(self, user_id: str, username: str, elo_rating: int = 1000,
                     socket_id: str = "") -> Dict:
        """Add player to Redis queue."""
        
        player = Player(
            user_id=user_id,
            username=username,
            elo_rating=elo_rating,
            queue_time=datetime.utcnow().isoformat(),
            socket_id=socket_id
        )
        
        try:
            # ATOMIC OPERATION: Store player data + add to queue
            pipe = self.redis.pipeline()
            
            # Store player info
            pipe.set(
                f"{self.PLAYER_KEY_PREFIX}{user_id}",
                player.to_json(),
                ex=3600  # 1-hour TTL (auto-cleanup)
            )
            
            # Add to queue (score = timestamp for FIFO ordering)
            pipe.zadd(
                self.QUEUE_KEY,
                {user_id: datetime.utcnow().timestamp()}
            )
            
            pipe.execute()
            
            logger.info(f"Added {user_id} to queue | Queue size: {self.get_queue_size()}")
            return {"success": True, "user_id": user_id}
        
        except Exception as e:
            logger.error(f"Error adding to queue: {e}")
            return {"success": False, "error": str(e)}
    
    def remove_from_queue(self, user_id: str) -> bool:
        """Remove player from queue."""
        try:
            self.redis.zrem(self.QUEUE_KEY, user_id)
            self.redis.delete(f"{self.PLAYER_KEY_PREFIX}{user_id}")
            logger.info(f"Removed {user_id} from queue")
            return True
        except Exception as e:
            logger.error(f"Error removing from queue: {e}")
            return False
    
    def find_best_match(self, player_id: str, elo_tolerance: int = 200) -> Optional[str]:
        """Find best opponent using Redis ZRANGE."""
        try:
            # Get player's ELO
            player_data = self.redis.get(f"{self.PLAYER_KEY_PREFIX}{player_id}")
            if not player_data:
                return None
            
            player = Player.from_json(player_data)
            player_elo = player.elo_rating
            
            # Get all players in queue
            queue_user_ids = self.redis.zrange(self.QUEUE_KEY, 0, -1)
            
            best_match = None
            closest_diff = float('inf')
            
            for candidate_id in queue_user_ids:
                if candidate_id == player_id:
                    continue
                
                candidate_data = self.redis.get(f"{self.PLAYER_KEY_PREFIX}{candidate_id}")
                if not candidate_data:
                    continue
                
                candidate = Player.from_json(candidate_data)
                elo_diff = abs(player_elo - candidate.elo_rating)
                
                if elo_diff < closest_diff and elo_diff <= elo_tolerance:
                    closest_diff = elo_diff
                    best_match = candidate_id
            
            return best_match
        
        except Exception as e:
            logger.error(f"Error finding match: {e}")
            return None
    
    def attempt_matchmaking(self, challenge_id: str) -> Optional[Dict]:
        """Create match from queue."""
        try:
            if self.get_queue_size() < 2:
                return None
            
            # Get longest-waiting player
            queue_user_ids = self.redis.zrange(self.QUEUE_KEY, 0, 0)  # First (oldest)
            if not queue_user_ids:
                return None
            
            player1_id = queue_user_ids[0]
            
            # Find opponent
            player2_id = self.find_best_match(player1_id)
            if not player2_id:
                return None
            
            # Get player data
            player1_data = Player.from_json(self.redis.get(f"{self.PLAYER_KEY_PREFIX}{player1_id}"))
            player2_data = Player.from_json(self.redis.get(f"{self.PLAYER_KEY_PREFIX}{player2_id}"))
            
            # Create battle room
            room_id = f"room_{uuid.uuid4().hex[:12]}"
            battle_data = {
                "room_id": room_id,
                "player1": asdict(player1_data),
                "player2": asdict(player2_data),
                "challenge_id": challenge_id,
                "status": "in_progress",
                "created_at": datetime.utcnow().isoformat(),
                "player1_code": "",
                "player2_code": "",
                "player1_tests": 0,
                "player2_tests": 0,
                "total_tests": 0,
                "winner_id": None,
            }
            
            # ATOMIC: Remove from queue + store battle room
            pipe = self.redis.pipeline()
            
            # Remove both players from queue
            pipe.zrem(self.QUEUE_KEY, player1_id, player2_id)
            
            # Store battle room (1-hour TTL)
            pipe.set(
                f"{self.ROOM_KEY_PREFIX}{room_id}",
                json.dumps(battle_data),
                ex=3600
            )
            
            # Map player â†’ room (for reconnection)
            pipe.set(f"{self.PLAYER_TO_ROOM_KEY}{player1_id}", room_id, ex=3600)
            pipe.set(f"{self.PLAYER_TO_ROOM_KEY}{player2_id}", room_id, ex=3600)
            
            pipe.execute()
            
            logger.info(f"Match created: {player1_data.username} vs {player2_data.username} (Room: {room_id})")
            return battle_data
        
        except Exception as e:
            logger.error(f"Error in matchmaking: {e}")
            return None
    
    def get_queue_size(self) -> int:
        """Get current queue size."""
        return self.redis.zcard(self.QUEUE_KEY)
    
    def get_battle_room(self, room_id: str) -> Optional[Dict]:
        """Get battle room data."""
        data = self.redis.get(f"{self.ROOM_KEY_PREFIX}{room_id}")
        return json.loads(data) if data else None
    
    def get_player_battle_room(self, user_id: str) -> Optional[Dict]:
        """Get player's current battle room."""
        room_id = self.redis.get(f"{self.PLAYER_TO_ROOM_KEY}{user_id}")
        if room_id:
            return self.get_battle_room(room_id)
        return None
    
    def update_test_results(self, room_id: str, player_id: str,
                          tests_passed: int, total_tests: int) -> bool:
        """Update test results in Redis."""
        try:
            battle_data = self.get_battle_room(room_id)
            if not battle_data:
                return False
            
            battle_data['total_tests'] = total_tests
            
            if player_id == battle_data['player1']['user_id']:
                battle_data['player1_tests'] = tests_passed
            else:
                battle_data['player2_tests'] = tests_passed
            
            # Check if won
            if tests_passed == total_tests:
                battle_data['winner_id'] = player_id
                battle_data['status'] = 'completed'
            
            # Store updated battle data
            self.redis.set(
                f"{self.ROOM_KEY_PREFIX}{room_id}",
                json.dumps(battle_data),
                ex=3600
            )
            
            return True
        
        except Exception as e:
            logger.error(f"Error updating results: {e}")
            return False


# Global instance
matchmaking_system = RedisMatchmakingQueue()
```

---

## Part 2: Session Persistence (Database)

### Problem: Page Refresh Loses Battle State

**Current Issue:**
```
User refreshing browser:
1. Socket disconnects
2. disconnect() handler removes from battle
3. User reconnects with new socket_id
4. Battle is lost
```

### Solution: Session Persistence with PostgreSQL

**Install PostgreSQL:**
```bash
# Docker
docker run -d -p 5432:5432 -e POSTGRES_PASSWORD=password postgres:15

# Or local: brew install postgresql
```

**File:** `backend/src/db/models.py` (NEW)

```python
"""SQLAlchemy models for persistence."""

from sqlalchemy import create_engine, Column, String, Integer, DateTime, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from datetime import datetime
import os

DATABASE_URL = os.getenv(
    'DATABASE_URL',
    'postgresql://postgres:password@localhost:5432/python_duel'
)

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()


class User(Base):
    """User data persistence."""
    __tablename__ = "users"
    
    user_id = Column(String, primary_key=True)
    username = Column(String, unique=True)
    elo_rating = Column(Integer, default=1000)
    created_at = Column(DateTime, default=datetime.utcnow)


class BattleSession(Base):
    """Active battle persistence."""
    __tablename__ = "battle_sessions"
    
    room_id = Column(String, primary_key=True)
    player1_id = Column(String, index=True)
    player2_id = Column(String, index=True)
    challenge_id = Column(String)
    
    player1_code = Column(String, default="")
    player2_code = Column(String, default="")
    player1_tests = Column(Integer, default=0)
    player2_tests = Column(Integer, default=0)
    total_tests = Column(Integer, default=0)
    
    status = Column(String)  # "in_progress", "completed"
    winner_id = Column(String, nullable=True)
    
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


# Create tables
Base.metadata.create_all(bind=engine)
```

**File:** `backend/src/api/main.py` (MODIFIED - Session Recovery)

```python
from db.models import SessionLocal, BattleSession, User

@sio.event
async def connect(sid, environ):
    """Handle reconnection with session recovery."""
    
    # Extract user_id from query params
    query_params = environ.get('QUERY_STRING', '')
    user_id = None
    
    if 'user_id=' in query_params:
        user_id = query_params.split('user_id=')[1].split('&')[0]
    
    logger.info(f"Client connected: {sid}")
    
    # CHECK: Is this user already in a battle?
    if user_id:
        db = SessionLocal()
        try:
            # Get active battle sessions
            active_battle = db.query(BattleSession).filter(
                (BattleSession.player1_id == user_id) |
                (BattleSession.player2_id == user_id),
                BattleSession.status == "in_progress"
            ).first()
            
            if active_battle:
                # RECOVER SESSION
                logger.info(f"Recovering battle session: {active_battle.room_id}")
                
                await sio.emit('session_recovered', {
                    'room_id': active_battle.room_id,
                    'player1_code': active_battle.player1_code,
                    'player2_code': active_battle.player2_code,
                    'player1_tests': active_battle.player1_tests,
                    'player2_tests': active_battle.player2_tests,
                    'total_tests': active_battle.total_tests,
                }, to=sid)
        
        finally:
            db.close()
    
    await sio.emit('connection_response', {'data': 'Connected to server'}, to=sid)


@sio.event
async def submit_code(sid, data):
    """Submit code - persist to database."""
    try:
        user_id = data.get('user_id')
        room_id = data.get('room_id')
        code = data.get('code', '')
        
        # ... existing code validation ...
        
        # Execute code
        execution_result = execute_code(code, test_cases, func_name, timeout=5)
        
        # PERSIST to database
        db = SessionLocal()
        try:
            battle = db.query(BattleSession).filter_by(room_id=room_id).first()
            
            if not battle:
                db.close()
                await sio.emit('error', {'message': 'Battle not found'}, to=sid)
                return
            
            # Update code and test results
            if user_id == battle.player1_id:
                battle.player1_code = code
                battle.player1_tests = execution_result.passed_tests
            else:
                battle.player2_code = code
                battle.player2_tests = execution_result.passed_tests
            
            battle.total_tests = execution_result.total_tests
            
            # Check if won
            if execution_result.passed_tests == execution_result.total_tests:
                battle.winner_id = user_id
                battle.status = 'completed'
            
            db.commit()
            logger.info(f"Battle state persisted: {room_id}")
        
        finally:
            db.close()
        
        # Broadcast to both players
        await sio.emit('code_submission', {
            'user_id': user_id,
            'passed_tests': execution_result.passed_tests,
            'total_tests': execution_result.total_tests,
        }, to=room_id)
    
    except Exception as e:
        logger.error(f"Error in submit_code: {e}")
        await sio.emit('error', {'message': str(e)}, to=sid)
```

---

## Part 3: Scaling Checklist

### Immediate (5,000 Users)
- [ ] Replace `matchmaking.py` with `redis_matchmaking.py`
- [ ] Add PostgreSQL for battle persistence
- [ ] Implement session recovery on reconnect
- [ ] Set Redis TTL to 1 hour (auto-cleanup)
- [ ] Use Docker Compose for Redis + PostgreSQL + Backend

### Mid-term (50,000 Users)
- [ ] Add Redis Cluster (horizontal sharding)
- [ ] Implement queue rate limiting
- [ ] Use message queue (RabbitMQ) for slow tasks
- [ ] Add CDN for frontend assets
- [ ] Implement user authentication + JWT

### Long-term (500,000+ Users)
- [ ] Kubernetes deployment
- [ ] Multi-region deployment (India, US, EU)
- [ ] GraphQL API for real-time subscriptions
- [ ] User analytics pipeline
- [ ] Sponsorship/advertising models

---

## Docker Compose (Updated for Distributed)

**File:** `docker-compose.yml` (UPDATED)

```yaml
version: '3.8'

services:
  backend:
    build: ./docker
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - DATABASE_URL=postgresql://user:password@postgres:5432/python_duel
    depends_on:
      - redis
      - postgres
    networks:
      - python-duel-network

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - python-duel-network

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=python_duel
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - python-duel-network

volumes:
  redis_data:
  postgres_data:

networks:
  python-duel-network:
    driver: bridge
```

**Launch all services:**
```bash
docker-compose up -d

# Verify
redis-cli ping              # PONG
psql postgresql://user:password@localhost:5432/python_duel
curl http://localhost:8000/api/health
```

---

## Performance Comparison

| Metric | In-Memory (50 users) | Redis (5,000 users) | Distributed (50K+) |
|--------|---|---|---|
| Queue Lookup | O(n) local | O(n) Redis | O(log n) sharded |
| Failover Time | âˆž (crash) | <1s | <100ms |
| Memory/Server | 100MB | 20MB | 20MB |
| Horizontal Scale | âŒ | âœ… | âœ… |
| Session Persistence | âŒ | âœ… | âœ… |

---

**Redis + PostgreSQL = Production-Ready at Scale ðŸš€**
